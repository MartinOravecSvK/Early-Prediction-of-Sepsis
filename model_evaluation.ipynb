{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd33e6e-3aa3-476a-9878-f08ee7a515ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same number of sepsis label = 0 as there are sepsis label =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5015e5-c4a1-4c0c-947f-ab58cf1c7722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lewis\\anaconda3\\envs\\lmm\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xgboost\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e3752d-b2a6-4c2b-8b2a-c0a88b364e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.get_data as get_data\n",
    "from utils.impute_methods import impute_linear_interpolation\n",
    "from utils.feature_engineering import preprecess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a717d42-9ff5-4123-9a35-0630b3021422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232f3be1-0d5f-4005-8e17-f7188a799949",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af995d2-f7ed-4528-817f-f620919d12ee",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0ba08b-0faf-470d-ba70-97802a80bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, patient_ids, X, y, max_length, device):\n",
    "        self.patient_ids = patient_ids\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pid = self.patient_ids[index]\n",
    "        patient_data = self.X.loc[pid]\n",
    "        X_train, seq_length = prepare_patient_data(patient_data, self.max_length)\n",
    "        y_train = torch.tensor(self.y.loc[pid].values, dtype=torch.float32)\n",
    "\n",
    "        # Ensure y_train is appropriately padded or trimmed to match X_train's length\n",
    "        if len(y_train) > self.max_length:\n",
    "            y_train = y_train[:self.max_length]\n",
    "        elif len(y_train) < self.max_length:\n",
    "            y_train = pad(torch.tensor(y_train, dtype=torch.float32), (0, self.max_length - len(y_train)), value=0)\n",
    "        \n",
    "        return X_train, y_train, len(y_train)\n",
    "        # return X_train, y_train, seq_length\n",
    "\n",
    "\n",
    "def prepare_patient_data(patient_data, max_length): \n",
    "        # Standardizing the data\n",
    "        scaler = StandardScaler()\n",
    "        features = scaler.fit_transform(patient_data)\n",
    "        # Padding\n",
    "        padded_features = np.zeros((max_length, features.shape[1]))\n",
    "        sequence_length = min(max_length, features.shape[0])\n",
    "        padded_features[:sequence_length] = features[:sequence_length]\n",
    "        return torch.tensor(padded_features, dtype=torch.float32), sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55eda4c-a0b8-4b16-84ac-162981059bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20337\n",
      "   40337\n",
      "Dataset loaded into a MultiIndex DataFrame.\n"
     ]
    }
   ],
   "source": [
    "dataset_raw, patient_id_map = get_data.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9aceb3-9484-4563-a4aa-3390c590d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_groups = dataset_raw.groupby(level=\"patient_id\")[\"SepsisLabel\"].max()\n",
    "patients_sepsis = sepsis_groups[sepsis_groups == 1].index\n",
    "patients_no_sepsis = sepsis_groups[sepsis_groups == 0].index\n",
    "patients_no_sepsis_sample = sepsis_groups.loc[patients_no_sepsis].sample(n=len(patients_sepsis)).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be92a495-b259-4647-9077-9ce35c5e2405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SepsisLabel\n",
       "0    2932\n",
       "1    2932\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = patients_no_sepsis_sample.append(patients_sepsis)\n",
    "\n",
    "# Get the equal number of sepsis and non-sepsis patients and shuffle\n",
    "dataset = dataset_raw.loc[indices].sample(frac=1)\n",
    "\n",
    "# Check that there is equal number of sepsis and non-sepsis patients\n",
    "dataset.groupby(level=\"patient_id\")[\"SepsisLabel\"].max().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc1e106-e963-4bd3-aca5-4617ffd635f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_proportion = 0.2\n",
    "# num_patients = len(dataset.index.levels[0])\n",
    "# subset_size = int(subset_proportion * num_patients)\n",
    "# print(f\"Test set size: {subset_size} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a212ac-a163-4765-9225-4b4b61fcbf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279461, 41)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c59afe0-1028-440d-9251-7ce9ec804509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linearly interpolating:\n",
      "HR\n",
      "O2Sat\n",
      "SBP\n",
      "MAP\n",
      "DBP\n",
      "Resp\n"
     ]
    }
   ],
   "source": [
    "columns_to_linearly_interpolate = [\n",
    "    'HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp'\n",
    "]\n",
    "\n",
    "# Linear Interpolation\n",
    "print(\"Linearly interpolating:\")\n",
    "for col in columns_to_linearly_interpolate:\n",
    "    if col != 'SepsisLabel':  # Ensure we do not interpolate 'SepsisLabel'\n",
    "        dataset = impute_linear_interpolation(dataset, col)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1610e1d0-a98c-4307-9ee0-4a00a0c15735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nan_indicators(df):\n",
    "    for column in df.columns:\n",
    "        df[column + '_nan'] = df[column].isna().astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c98273-bce0-4de5-926c-247a64f8ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_nan_indicators(dataset)\n",
    "\n",
    "# Engineered\n",
    "XX, y_engineered = preprecess_data(X)\n",
    "new_feature_names = [f\"new_feature_{i}\" for i in range(XX.shape[1])]\n",
    "XX_df = pd.DataFrame(XX, columns=new_feature_names, index=X.index)\n",
    "X_engineered = pd.concat([X, XX_df], axis=1)\n",
    "\n",
    "# Base\n",
    "X = dataset.drop('SepsisLabel', axis=1) \n",
    "y = dataset['SepsisLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b6f058b-33a6-434b-bb16-b7179107aa14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains NaN or infinite values. Handling...\n",
      "Data contains NaN or infinite values. Handling...\n"
     ]
    }
   ],
   "source": [
    "if X_engineered.isin([np.nan, np.inf, -np.inf]).any().any():\n",
    "    print(\"Data contains NaN or infinite values. Handling...\")\n",
    "    # Replace infinite values with NaN so they can be filled too\n",
    "    X_engineered.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # First apply forward fill\n",
    "    X_engineered.fillna(method='ffill', inplace=True)\n",
    "    # Then apply backward fill for any remaining NaNs\n",
    "    X_engineered.fillna(method='bfill', inplace=True)\n",
    "\n",
    "if X.isin([np.nan, np.inf, -np.inf]).any().any():\n",
    "    print(\"Data contains NaN or infinite values. Handling...\")\n",
    "    # Replace infinite values with NaN so they can be filled too\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # First apply forward fill\n",
    "    X.fillna(method='ffill', inplace=True)\n",
    "    # Then apply backward fill for any remaining NaNs\n",
    "    X.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Ensure no NaNs or infinities in the target variable as well\n",
    "if y.isin([np.nan, np.inf, -np.inf]).any():\n",
    "    print(\"Target contains NaN or infinite values. Handling...\")\n",
    "    y.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    y.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf738edc-e01b-4980-81d0-0d7a71775e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length (inputs will be padded to):  336\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum sequence length for padding\n",
    "# Yes it's really high, 336, consider making it larger to accommodate actual test set\n",
    "max_length = X.groupby('patient_id').size().max()\n",
    "print(\"Max length (inputs will be padded to): \", max_length)\n",
    "\n",
    "X_patient_ids = X.index.get_level_values('patient_id').unique()\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_engineered_patient_ids = X_engineered.index.get_level_values('patient_id').unique()\n",
    "_, X_engineered_test, _, y_engineered_test = train_test_split(X_engineered, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86409435-5388-4306-b5ba-cc567febe47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55893, 81)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3149cfb1-8a28-4f54-8f8e-9c3061023034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55893, 301)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_engineered_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbc33019-2ff8-4f93-bfc9-4cf9f481c5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55893,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca3b6acd-94e3-4c0f-8455-4febfc64d879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55893,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_engineered_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905f992-d578-45ca-952a-5d0eb377f89d",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30024663-1468-4a00-aed1-29d9b19ab8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xgboost\n",
    "xgb_path = \"models/saved/xgboost_model1.mdl\"\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.load_model(xgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1e3d33a-65d0-4855-9d5d-c5f1885d5cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 176, got 81",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xgb_pred \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lmm\\lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lmm\\lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lmm\\lib\\site-packages\\xgboost\\core.py:2428\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2425\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2426\u001b[0m         )\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2428\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2430\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2431\u001b[0m         )\n\u001b[0;32m   2433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[0;32m   2434\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 176, got 81"
     ]
    }
   ],
   "source": [
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42ddfb-1bc2-4a47-8ad1-57a34e89baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformers\n",
    "transformers_dir = os.getcwd() + \"/models/transformer\"\n",
    "transformer_paths = [os.path.join(transformers_dir, path) for path in os.listdir(transformers_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f97cac-9118-4cf5-afaa-e39692612426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
