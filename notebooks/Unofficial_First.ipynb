{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5046131-8973-4c66-8a2e-682324d65305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# Why not use mixture of experts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c24c5cc-49b0-40b2-a885-0c65aa274634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Geniuses that worked on hypertools did not update certain package and thus it produces warnings (they break jupyter lab)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Comment out if you don't want to see all of the values being printed (i.e. default)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# utils_path = os.path.join(current_dir, '..', 'utils')\n",
    "utils_path = os.path.join(current_dir, '../')\n",
    "utils_abs_path = os.path.abspath(utils_path)\n",
    "if utils_abs_path not in sys.path:\n",
    "    sys.path.append(utils_abs_path)\n",
    "\n",
    "import utils.get_data as get_data\n",
    "# from impute_methods import *\n",
    "from utils.impute_methods import impute_linear_interpolation\n",
    "\n",
    "DATA_PATH = get_data.get_dataset_abspath()\n",
    "\n",
    "training_setA_path = DATA_PATH + 'training_setA'\n",
    "training_setB_path = DATA_PATH + 'training_setB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f6cb9b-e7cc-403a-b905-a62af86d88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heart_rate_data(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    dataset['HR'].hist(bins=50)\n",
    "    plt.title('Distribution of Heart Rate')\n",
    "    plt.xlabel('Heart Rate')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    # You can also get a quick statistical summary\n",
    "    print(dataset['HR'].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb50c9a9-9558-4ae1-97a8-e622c521313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20337\n",
      "   40337\n",
      "Dataset loaded into a MultiIndex DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Loads the dataset\n",
    "\n",
    "# Sepsis related test values / variables / columns\n",
    "sep_col = ['BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST',\n",
    "             'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
    "             'Bilirubin_total', 'Hct', 'Hgb', 'PTT', 'WBC', 'Platelets',\n",
    "             'Bilirubin_direct', 'Fibrinogen']\n",
    "\n",
    "# Continues Health Indicators\n",
    "con_col = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2']\n",
    "\n",
    "# The original way of getting data shouldn't work as there isn't a concept of individual patient file in it\n",
    "# It just gets the data completely into a dataframe and each of the time data is one row\n",
    "# dataset = get_data.get_dataset_as_df()\n",
    "\n",
    "dataset, patient_id_map = get_data.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf90cc6-ee19-4eae-81e9-88981a73a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for patient ID: 1.0, File: p017721.psv\n"
     ]
    }
   ],
   "source": [
    "# for patient_id, file_name in patient_id_map.items():\n",
    "#     print(type(dataset.loc[patient_id]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e4ab624-7a23-4070-b00c-cfca8ebc9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_linearly_interpolate = [\n",
    "    'HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp'\n",
    "]\n",
    "columns_to_ffill = [\n",
    "    'Temp', 'Glucose', 'Potassium', 'Calcium', \n",
    "    'Magnesium', 'Chloride', 'Hct', 'Hgb', 'WBC', 'Platelets'\n",
    "]\n",
    "columns_to_drop = [\n",
    "    'SepsisLabel', 'TroponinI'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f03ff48c-1b03-45d6-8a9a-e6bffa7c7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_missing_information(patient_data, columns):\n",
    "    # temp_data holds the information from the patient file as well as the features that will be calculated\n",
    "    temp_data = np.array(patient_data)\n",
    "\n",
    "    # Calculate 3 features for each column, 2 respective of the frequency of NaN values and 1 respective of the change in recorded values\n",
    "    for column in columns:\n",
    "        data = np.array(patient_data[column])\n",
    "        nan_pos = np.where(~np.isnan(data))[0]\n",
    "        \n",
    "        # Measurement frequency sequence\n",
    "        interval_f1 = data.copy()\n",
    "        # Measurement time interval\n",
    "        interval_f2 = data.copy()\n",
    "\n",
    "        # If all the values are NaN\n",
    "        if (len(nan_pos) == 0):\n",
    "            interval_f1[:] = 0\n",
    "            temp_data = np.column_stack((temp_data, interval_f1))\n",
    "            interval_f2[:] = -1\n",
    "            temp_data = np.column_stack((temp_data, interval_f2))\n",
    "        else :\n",
    "            # Puts number of measurements into temp_data\n",
    "            interval_f1[: nan_pos[0]] = 0\n",
    "            for p in range(len(nan_pos)-1):\n",
    "                interval_f1[nan_pos[p]: nan_pos[p+1]] = p + 1\n",
    "            interval_f1[nan_pos[-1] :] = len(nan_pos)\n",
    "            temp_data = np.column_stack((temp_data, interval_f1))\n",
    "\n",
    "            # Puts the frequency of measurements into temp_data\n",
    "            interval_f2[:nan_pos[0]] = -1\n",
    "            for q in range(len(nan_pos) - 1):\n",
    "                length = nan_pos[q+1] - nan_pos[q]\n",
    "                for l in range(length):\n",
    "                    interval_f2[nan_pos[q] + l] = l\n",
    "\n",
    "            length = len(patient_data) - nan_pos[-1]\n",
    "            for l in range(length):\n",
    "                interval_f2[nan_pos[-1] + l] = l\n",
    "            temp_data = np.column_stack((temp_data, interval_f2))\n",
    "\n",
    "        # Differential features\n",
    "        # These capture the change in values that have been recorded (quite simply as well but it should be just fine)\n",
    "        diff_f = data.copy()\n",
    "        diff_f = diff_f.astype(float)\n",
    "        if len(nan_pos) <= 1:\n",
    "            diff_f[:] = np.NaN\n",
    "            temp_data = np.column_stack((temp_data, diff_f))\n",
    "        else:\n",
    "            diff_f[:nan_pos[1]] = np.NaN\n",
    "            for p in range(1, len(nan_pos)-1):\n",
    "                diff_f[nan_pos[p] : nan_pos[p+1]] = data[nan_pos[p]] - data[nan_pos[p-1]]\n",
    "            diff_f[nan_pos[-1]:] = data[nan_pos[-1]] - data[nan_pos[-2]]\n",
    "            temp_data = np.column_stack((temp_data, diff_f))\n",
    "    \n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34b01ff8-e0f1-408d-8582-d1e35e53b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_slide_window(patient_data, columns):\n",
    "    \n",
    "    window_size = 6\n",
    "    features = {}\n",
    "    \n",
    "    for column in columns:\n",
    "        series = patient_data[column]\n",
    "\n",
    "        features[f'{column}_max'] = series.rolling(window=window_size, min_periods=1).max()\n",
    "        features[f'{column}_min'] = series.rolling(window=window_size, min_periods=1).min()\n",
    "        features[f'{column}_mean'] = series.rolling(window=window_size, min_periods=1).mean()\n",
    "        features[f'{column}_median'] = series.rolling(window=window_size, min_periods=1).median()\n",
    "        features[f'{column}_std'] = series.rolling(window=window_size, min_periods=1).std()\n",
    "        \n",
    "        # For calculating std dev of differences, use diff() then apply rolling std\n",
    "        diff_std = series.diff().rolling(window=window_size, min_periods=1).std()\n",
    "        features[f'{column}_diff_std'] = diff_std\n",
    "\n",
    "    # Convert the dictionary of features into a DataFrame\n",
    "    features_df = pd.DataFrame(features)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3094ea18-fd79-4824-9ba9-06c5208a1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_score(patient_data):\n",
    "    \"\"\"\n",
    "    Gives score assocciated with the patient data according to the scoring systems of NEWS, SOFA and qSOFA\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = np.zeros((len(patient_data), 8))\n",
    "    \n",
    "    for ii in range(len(patient_data)):\n",
    "        HR = patient_data[ii, 0]\n",
    "        if HR == np.nan:\n",
    "            HR_score = np.nan\n",
    "        elif (HR <= 40) | (HR >= 131):\n",
    "            HR_score = 3\n",
    "        elif 111 <= HR <= 130:\n",
    "            HR_score = 2\n",
    "        elif (41 <= HR <= 50) | (91 <= HR <= 110):\n",
    "            HR_score = 1\n",
    "        else:\n",
    "            HR_score = 0\n",
    "        scores[ii, 0] = HR_score\n",
    "\n",
    "        Temp = patient_data[ii, 2]\n",
    "        if Temp == np.nan:\n",
    "            Temp_score = np.nan\n",
    "        elif Temp <= 35:\n",
    "            Temp_score = 3\n",
    "        elif Temp >= 39.1:\n",
    "            Temp_score = 2\n",
    "        elif (35.1 <= Temp <= 36.0) | (38.1 <= Temp <= 39.0):\n",
    "            Temp_score = 1\n",
    "        else:\n",
    "            Temp_score = 0\n",
    "        scores[ii, 1] = Temp_score\n",
    "\n",
    "        Resp = patient_data[ii, 6]\n",
    "        if Resp == np.nan:\n",
    "            Resp_score = np.nan\n",
    "        elif (Resp < 8) | (Resp > 25):\n",
    "            Resp_score = 3\n",
    "        elif 21 <= Resp <= 24:\n",
    "            Resp_score = 2\n",
    "        elif 9 <= Resp <= 11:\n",
    "            Resp_score = 1\n",
    "        else:\n",
    "            Resp_score = 0\n",
    "        scores[ii, 2] = Resp_score\n",
    "\n",
    "        Creatinine = patient_data[ii, 19]\n",
    "        if Creatinine == np.nan:\n",
    "            Creatinine_score = np.nan\n",
    "        elif Creatinine < 1.2:\n",
    "            Creatinine_score = 0\n",
    "        elif Creatinine < 2:\n",
    "            Creatinine_score = 1\n",
    "        elif Creatinine < 3.5:\n",
    "            Creatinine_score = 2\n",
    "        else:\n",
    "            Creatinine_score = 3\n",
    "        scores[ii, 3] = Creatinine_score\n",
    "\n",
    "        MAP = patient_data[ii, 4]\n",
    "        if MAP == np.nan:\n",
    "            MAP_score = np.nan\n",
    "        elif MAP >= 70:\n",
    "            MAP_score = 0\n",
    "        else:\n",
    "            MAP_score = 1\n",
    "        scores[ii, 4] = MAP_score\n",
    "\n",
    "        SBP = patient_data[ii, 3]\n",
    "        Resp = patient_data[ii, 6]\n",
    "        if SBP + Resp == np.nan:\n",
    "            qsofa = np.nan\n",
    "        elif (SBP <= 100) & (Resp >= 22):\n",
    "            qsofa = 1\n",
    "        else:\n",
    "            qsofa = 0\n",
    "        scores[ii, 5] = qsofa\n",
    "\n",
    "        Platelets = patient_data[ii, 30]\n",
    "        if Platelets == np.nan:\n",
    "            Platelets_score = np.nan\n",
    "        elif Platelets <= 50:\n",
    "            Platelets_score = 3\n",
    "        elif Platelets <= 100:\n",
    "            Platelets_score = 2\n",
    "        elif Platelets <= 150:\n",
    "            Platelets_score = 1\n",
    "        else:\n",
    "            Platelets_score = 0\n",
    "        scores[ii, 6] = Platelets_score\n",
    "\n",
    "        Bilirubin = patient_data[ii, 25]\n",
    "        if Bilirubin == np.nan:\n",
    "            Bilirubin_score = np.nan\n",
    "        elif Bilirubin < 1.2:\n",
    "            Bilirubin_score = 0\n",
    "        elif Bilirubin < 2:\n",
    "            Bilirubin_score = 1\n",
    "        elif Bilirubin < 6:\n",
    "            Bilirubin_score = 2\n",
    "        else:\n",
    "            Bilirubin_score = 3\n",
    "        scores[ii, 7] = Bilirubin_score\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2975050-0b04-412e-bea6-a12702b2debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(patient_data):\n",
    "    # Get the column with Sepsis Label as it is not the same for each row (check documentation)\n",
    "    labels = np.array(patient_data['SepsisLabel'])\n",
    "    patient_data = patient_data.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Gets information from the missing variables \n",
    "    # This can be useful as it shows the clinical judgment, the test has not been ordered \n",
    "    #                              (probably a good decision we should take into account)\n",
    "    temp_data = feature_missing_information(patient_data, sep_col + con_col)\n",
    "    temp = pd.DataFrame(temp_data)\n",
    "    # To complete the data use forward-filling strategy\n",
    "    temp = temp.fillna(method='ffill')\n",
    "    # These are also the first set of features\n",
    "    # In this configutation 99 (66 + 33 or 3 per column) features to be precise\n",
    "    # They are also time indifferent\n",
    "    print(temp)\n",
    "    features_A = np.array(temp)\n",
    "    print(features_A)\n",
    "    # The team did not use DBP, not sure why, might investigate this\n",
    "    # columns = ['HR', 'O2Sat', 'SBP', 'MAP', 'Resp', 'DBP']\n",
    "    \n",
    "    # six-hour slide window statistics of selected columns\n",
    "    columns = ['HR', 'O2Sat', 'SBP', 'MAP', 'Resp']\n",
    "    features_B = feature_slide_window(patient_data, columns)\n",
    "\n",
    "    # Score features based according to NEWS, SOFA and qSOFA\n",
    "    features_C = features_score(features_A)\n",
    "    \n",
    "    features = np.column_stack([features_A, features_B, features_C])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55b8a3b1-2dbd-4a57-b3d1-e788e2e34604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1      2       3      4     5     6    7    8     9    ...    128  \\\n",
      "0   88.0  100.0  35.60  117.00  73.00  53.0   8.5  NaN -1.5   NaN  ...    NaN   \n",
      "1   87.5  100.0  35.65  112.00  69.50  51.0  12.0  NaN -3.0   NaN  ...  -3.50   \n",
      "2   88.0   99.0  36.20  103.00  65.00  49.0  14.0  NaN -3.0   NaN  ...  -4.50   \n",
      "3   88.0   95.5  36.75   93.50  71.50  38.5  19.0  NaN  0.0   NaN  ...   6.50   \n",
      "4   88.0   96.0  37.00  112.50  65.50  46.5  18.5  NaN  0.0   NaN  ...  -6.00   \n",
      "5   88.0   99.0  37.05  123.00  73.00  51.5  15.0  NaN  0.0   NaN  ...   7.50   \n",
      "6   88.0   99.0  36.95  103.00  58.50  40.5  12.0  NaN  0.0   NaN  ... -14.50   \n",
      "7   88.0  100.0  37.00  133.00  78.00  52.0  16.0  NaN  0.0   NaN  ...  19.50   \n",
      "8   88.0  100.0  36.90  100.00  61.00  44.0  12.0  NaN  0.0   NaN  ... -17.00   \n",
      "9   88.0  100.0  36.90   96.00  58.00  42.0  12.0  NaN  0.0   NaN  ...  -3.00   \n",
      "10  88.0   99.5  36.95   91.50  56.00  41.0  12.0  NaN  0.0   NaN  ...  -2.00   \n",
      "11  88.0  100.0  36.80  112.00  64.00  42.0  17.0  NaN  0.0   NaN  ...   8.00   \n",
      "12  88.0  100.0  36.90  101.00  58.00  39.0  13.0  NaN  0.0   NaN  ...  -6.00   \n",
      "13  88.0  100.0  36.90   98.00  59.00  41.0  16.0  NaN  0.0  26.0  ...   1.00   \n",
      "14  88.0  100.0  37.00  104.00  64.00  44.0  12.0  NaN  0.0  26.0  ...   5.00   \n",
      "15  88.0  100.0  37.00  116.00  73.00  53.0  12.0  NaN  0.0  26.0  ...   9.00   \n",
      "16  88.0  100.0  36.90  120.00  70.00  48.0  13.0  NaN  0.0  26.0  ...  -3.00   \n",
      "17  88.0  100.0  36.90  105.00  62.00  43.0  17.0  NaN  0.0  26.0  ...  -8.00   \n",
      "18  88.0   99.0  36.83  123.50  67.67  60.0  15.0  NaN  0.0  26.0  ...   5.67   \n",
      "19  88.0   99.0  36.83  123.50  70.17  57.5  15.0  NaN  0.0  26.0  ...   2.50   \n",
      "20  88.0   98.0  36.83  121.00  80.00  58.0  16.0  NaN  0.0  26.0  ...   9.83   \n",
      "21  77.0  100.0  36.83  130.50  82.50  58.0  18.0  NaN  0.0  26.0  ...   2.50   \n",
      "22  63.0   97.5  36.89  104.75  60.00  44.5  17.5  NaN  0.0  26.0  ... -22.50   \n",
      "23  60.0   96.0  36.89   99.00  60.00  44.0  18.0  NaN  0.0  26.0  ...   0.00   \n",
      "24  60.0   96.0  36.89   99.00  60.00  44.0  18.0  NaN  0.0  26.0  ...   0.00   \n",
      "25  71.0   98.0  36.89  111.00  57.33  49.0  18.0  NaN  0.0  26.0  ...  -2.67   \n",
      "26  73.0  100.0  36.61  126.50  72.00  50.0  17.0  NaN  0.0  26.0  ...  14.67   \n",
      "27  74.0   99.0  36.61  113.00  62.00  41.0  21.0  NaN  0.0  26.0  ... -10.00   \n",
      "\n",
      "     129  130   131   132  133  134  135  136  137  \n",
      "0    1.0  0.0   NaN   1.0  0.0  NaN  0.0 -1.0  NaN  \n",
      "1    2.0  0.0  -2.0   2.0  0.0  3.5  0.0 -1.0  NaN  \n",
      "2    3.0  0.0  -2.0   3.0  0.0  2.0  0.0 -1.0  NaN  \n",
      "3    4.0  0.0 -10.5   4.0  0.0  5.0  0.0 -1.0  NaN  \n",
      "4    5.0  0.0   8.0   5.0  0.0 -0.5  0.0 -1.0  NaN  \n",
      "5    6.0  0.0   5.0   6.0  0.0 -3.5  0.0 -1.0  NaN  \n",
      "6    7.0  0.0 -11.0   7.0  0.0 -3.0  0.0 -1.0  NaN  \n",
      "7    8.0  0.0  11.5   8.0  0.0  4.0  0.0 -1.0  NaN  \n",
      "8    9.0  0.0  -8.0   9.0  0.0 -4.0  0.0 -1.0  NaN  \n",
      "9   10.0  0.0  -2.0  10.0  0.0  0.0  0.0 -1.0  NaN  \n",
      "10  11.0  0.0  -1.0  11.0  0.0  0.0  0.0 -1.0  NaN  \n",
      "11  12.0  0.0   1.0  12.0  0.0  5.0  0.0 -1.0  NaN  \n",
      "12  13.0  0.0  -3.0  13.0  0.0 -4.0  0.0 -1.0  NaN  \n",
      "13  14.0  0.0   2.0  14.0  0.0  3.0  0.0 -1.0  NaN  \n",
      "14  15.0  0.0   3.0  15.0  0.0 -4.0  0.0 -1.0  NaN  \n",
      "15  16.0  0.0   9.0  16.0  0.0  0.0  0.0 -1.0  NaN  \n",
      "16  17.0  0.0  -5.0  17.0  0.0  1.0  0.0 -1.0  NaN  \n",
      "17  18.0  0.0  -5.0  18.0  0.0  4.0  0.0 -1.0  NaN  \n",
      "18  19.0  0.0  17.0  19.0  0.0 -2.0  0.0 -1.0  NaN  \n",
      "19  20.0  0.0  -2.5  20.0  0.0  0.0  0.0 -1.0  NaN  \n",
      "20  21.0  0.0   0.5  21.0  0.0  1.0  0.0 -1.0  NaN  \n",
      "21  22.0  0.0   0.0  22.0  0.0  2.0  0.0 -1.0  NaN  \n",
      "22  23.0  0.0 -13.5  23.0  0.0 -0.5  0.0 -1.0  NaN  \n",
      "23  24.0  0.0  -0.5  24.0  0.0  0.5  0.0 -1.0  NaN  \n",
      "24  24.0  1.0  -0.5  24.0  1.0  0.5  0.0 -1.0  NaN  \n",
      "25  25.0  0.0   5.0  25.0  0.0  0.0  0.0 -1.0  NaN  \n",
      "26  26.0  0.0   1.0  26.0  0.0 -1.0  0.0 -1.0  NaN  \n",
      "27  27.0  0.0  -9.0  27.0  0.0  4.0  0.0 -1.0  NaN  \n",
      "\n",
      "[28 rows x 138 columns]\n",
      "[[ 88.   100.    35.6  ...   0.    -1.      nan]\n",
      " [ 87.5  100.    35.65 ...   0.    -1.      nan]\n",
      " [ 88.    99.    36.2  ...   0.    -1.      nan]\n",
      " ...\n",
      " [ 71.    98.    36.89 ...   0.    -1.      nan]\n",
      " [ 73.   100.    36.61 ...   0.    -1.      nan]\n",
      " [ 74.    99.    36.61 ...   0.    -1.      nan]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frames_features = []\n",
    "frames_labels = []\n",
    "\n",
    "for patient_id in set(dataset.index.get_level_values(0)):\n",
    "    patient_data = dataset.loc[patient_id]\n",
    "    print(f\"Processing data for patient ID: {patient_id}, File: {patient_id_map[patient_id]}\", end='\\r')\n",
    "\n",
    "    features, labels = extract_features(patient_data)\n",
    "    features = pd.DataFrame(features)\n",
    "    labels = pd.DataFrame(labels)\n",
    "\n",
    "    frames_features.append(features)\n",
    "    frames_labels.append(labels)\n",
    "\n",
    "dat_features = np.array(pd.concat(frames_features))\n",
    "dat_labels = (np.array(pd.concat(frames_labels)))[:, 0]\n",
    "\n",
    "# Randomly shuffle the data\n",
    "index = [i for i in range(len(dat_labels))]\n",
    "np.random.shuffle(index)\n",
    "dat_features = dat_features[index]\n",
    "dat_labels = dat_labels[index]\n",
    "\n",
    "return dat_features, dat_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfb1530-8fc5-4878-b7ee-312ee37f4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished imputing HR\n",
      "Finished imputing O2Sat\n",
      "Finished imputing SBP\n",
      "Finished imputing MAP\n",
      "Finished imputing DBP\n",
      "Finished imputing Resp\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Imputes O2Sat using linear interpolation\n",
    "# Other methods might be better based on the data distribution (consider Spline or Polynomial Interpolation)\n",
    "\n",
    "# Impute SBP using linear interpolation\n",
    "# We can consider Forward Fill or Backward Fill if we assume the blood pressure should remain relatively stable\n",
    "\n",
    "# Impute MAP using linear interpolation\n",
    "# To be more sophiscticated the data can be imputed with custom models to take into account SBP and DBP as there might be correlation\n",
    "\n",
    "# Impute DBP using linear interpolation\n",
    "# Same as SBP, we might consider Spline\n",
    "\n",
    "# Impute Resp using linear interpolation\n",
    "# Same as SBP and DBP, we might consider Spline or Polynomial Interpolation\n",
    "\n",
    "\n",
    "'''\n",
    "columns_to_linearly_interpolate = [\n",
    "    'HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp'\n",
    "]\n",
    "for column in columns_to_linearly_interpolate:\n",
    "    dataset = impute_linear_interpolation(dataset, column)\n",
    "    print('Finished imputing ' + column)\n",
    "\n",
    "columns_to_ffill = [\n",
    "    'Temp', 'Glucose', 'Potassium', 'Calcium', \n",
    "    'Magnesium', 'Chloride', 'Hct', 'Hgb', 'WBC', 'Platelets'\n",
    "]\n",
    "for column in columns_to_ffill:\n",
    "    dataset[column].ffill(inplace=True)\n",
    "'''\n",
    "\n",
    "# Columns not imputed\n",
    "\n",
    "# They dropped Bilirubin_direct, TroponinI, Fibrinogen\n",
    "#            has relation, more complex if any, potentially\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataset = dataset.fillna\n",
    "\n",
    "# Use forward filling for some of the data\n",
    "\n",
    "# Best solution used sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce06dbb-c245-4fbe-9ee4-14fff851a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_missing_information(patient_data, columns):\n",
    "    temp = patiend_data\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a50a2b-c1fb-4d03-8d95-9a441eced99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR\n",
      "O2Sat\n",
      "Temp\n",
      "SBP\n",
      "MAP\n",
      "DBP\n",
      "Resp\n",
      "EtCO2\n",
      "BaseExcess\n",
      "HCO3\n",
      "FiO2\n",
      "pH\n",
      "PaCO2\n",
      "SaO2\n",
      "AST\n",
      "BUN\n",
      "Alkalinephos\n",
      "Calcium\n",
      "Chloride\n",
      "Creatinine\n",
      "Bilirubin_direct\n",
      "Glucose\n",
      "Lactate\n",
      "Magnesium\n",
      "Phosphate\n",
      "Potassium\n",
      "Bilirubin_total\n",
      "TroponinI\n",
      "Hct\n",
      "Hgb\n",
      "PTT\n",
      "WBC\n",
      "Fibrinogen\n",
      "Platelets\n",
      "Age\n",
      "Gender\n",
      "Unit1\n",
      "Unit2\n",
      "HospAdmTime\n",
      "ICULOS\n",
      "SepsisLabel\n"
     ]
    }
   ],
   "source": [
    "for patient_id in set(dataset.index.get_level_values(0)):\n",
    "    patient_data = multiindex_df.loc[patient_id]\n",
    "    print(f\"Processing data for patient ID: {patient_id}, File: {patient_id_map[patient_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd45fea-fcd6-4ff6-a873-8f0cb1d74d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ectract features\n",
    "\n",
    "def extract_features(patient_data):\n",
    "    # Get the column with Sepsis Label as it is not the same for each row (check documentation)\n",
    "    labels = np.array(patient_data['SepsisLabel'])\n",
    "    patient_data = patient_data.drop(columns=['SepsisLabel', 'TroponinI'])\n",
    "\n",
    "    # Gets information from the missing variables \n",
    "    # This can be useful as it shows the clinical judgment, the test has not been ordered \n",
    "    #                              (probably a good decision we should take into account)\n",
    "    temp_data = feature_missing_information(patient_data, sep_col + con_col)\n",
    "    temp = pd.DataFrame(temp_data)\n",
    "    # To complete the data use forward-filling strategy\n",
    "    temp = temp.fillna(method='ffill')\n",
    "    # These are also the first set of features\n",
    "    # In this configutation 66 features to be precise\n",
    "    # They are also time indifferent\n",
    "    features_A = np.array(temp)\n",
    "    \n",
    "\n",
    "    # some code\n",
    "    # Forward-Filling missing values\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e65180-1e29-4c5b-b326-1a4c1bd55adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Run feature extraction for each patient\n",
    "\n",
    "for c in dataset.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e78e00-c2ca-44a5-a852-90ec02818979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1ed9b-9a12-4986-8bb3-6586eed290c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
