{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5046131-8973-4c66-8a2e-682324d65305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# Why not use mixture of experts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c24c5cc-49b0-40b2-a885-0c65aa274634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Geniuses that worked on hypertools did not update certain package and thus it produces warnings (they break jupyter lab)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Comment out if you don't want to see all of the values being printed (i.e. default)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# utils_path = os.path.join(current_dir, '..', 'utils')\n",
    "utils_path = os.path.join(current_dir, '../')\n",
    "utils_abs_path = os.path.abspath(utils_path)\n",
    "if utils_abs_path not in sys.path:\n",
    "    sys.path.append(utils_abs_path)\n",
    "\n",
    "import utils.get_data as get_data\n",
    "# from impute_methods import *\n",
    "from utils.impute_methods import impute_linear_interpolation\n",
    "\n",
    "DATA_PATH = get_data.get_dataset_abspath()\n",
    "\n",
    "training_setA_path = DATA_PATH + 'training_setA'\n",
    "training_setB_path = DATA_PATH + 'training_setB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f6cb9b-e7cc-403a-b905-a62af86d88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heart_rate_data(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    dataset['HR'].hist(bins=50)\n",
    "    plt.title('Distribution of Heart Rate')\n",
    "    plt.xlabel('Heart Rate')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    # You can also get a quick statistical summary\n",
    "    print(dataset['HR'].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb50c9a9-9558-4ae1-97a8-e622c521313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20337\n",
      "   40337\n",
      "Dataset loaded into a MultiIndex DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Loads the dataset\n",
    "\n",
    "# Sepsis related test values / variables / columns\n",
    "sep_col = ['BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST',\n",
    "             'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
    "             'Bilirubin_total', 'Hct', 'Hgb', 'PTT', 'WBC', 'Platelets',\n",
    "             'Bilirubin_direct', 'Fibrinogen']\n",
    "\n",
    "# Continues Health Indicators\n",
    "con_col = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2']\n",
    "\n",
    "# The original way of getting data shouldn't work as there isn't a concept of individual patient file in it\n",
    "# It just gets the data completely into a dataframe and each of the time data is one row\n",
    "# dataset = get_data.get_dataset_as_df()\n",
    "\n",
    "dataset, patient_id_map = get_data.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf90cc6-ee19-4eae-81e9-88981a73a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for patient ID: 1.0, File: p017721.psv\n"
     ]
    }
   ],
   "source": [
    "# for patient_id, file_name in patient_id_map.items():\n",
    "#     print(type(dataset.loc[patient_id]))\n",
    "#     break\n",
    "\n",
    "for patient_id in set(dataset.index.get_level_values(0)):\n",
    "    patient_data = dataset.loc[patient_id]\n",
    "    print(f\"Processing data for patient ID: {patient_id}, File: {patient_id_map[patient_id]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ab624-7a23-4070-b00c-cfca8ebc9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_linearly_interpolate = [\n",
    "    'HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp'\n",
    "]\n",
    "columns_to_ffill = [\n",
    "    'Temp', 'Glucose', 'Potassium', 'Calcium', \n",
    "    'Magnesium', 'Chloride', 'Hct', 'Hgb', 'WBC', 'Platelets'\n",
    "]\n",
    "columns_to_drop = [\n",
    "    'SepsisLavel', 'TroponinI'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f03ff48c-1b03-45d6-8a9a-e6bffa7c7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_missing_information(patient_data, columns):\n",
    "    # temp_data holds the information from the patient file as well as the features that will be calculated\n",
    "    temp_data = np.array(patient_data)\n",
    "\n",
    "    # Calculate 3 features for each column, 2 respective of the frequency of NaN values and 1 respective of the change in recorded values\n",
    "    for column in columns:\n",
    "        data = np.array(patient_data[column])\n",
    "        nan_pos = np.where(~np.isnan(data))[0]\n",
    "        \n",
    "        # Measurement frequency sequence\n",
    "        interval_f1 = data.copy()\n",
    "        # Measurement time interval\n",
    "        interval_f2 = data.copy()\n",
    "\n",
    "        # If all the values are NaN\n",
    "        if (len(nan_pos) == 0):\n",
    "            interval_f1[:] = 0\n",
    "            temp_data = np.column_stack((temp_data, interval_f1))\n",
    "            interval_f2[:] = -1\n",
    "            temp_data = np.column_stack((temp_data, interval_f2))\n",
    "        else :\n",
    "            # Puts number of measurements into temp_data\n",
    "            interval_f1[: nan_pos[0]] = 0\n",
    "            for p in range(len(nan_pos)-1):\n",
    "                interval_f1[nan_pos[p]: nan_pos[p+1]] = p + 1\n",
    "            interval_f1[nan_pos[-1] :] = len(nan_pos)\n",
    "            temp_data = np.column_stack((temp_data, interval_f1))\n",
    "\n",
    "            # Puts the frequency of measurements into temp_data\n",
    "            interval_f2[:nan_pos[0]] = -1\n",
    "            for q in range(len(nan_pos) - 1):\n",
    "                length = nan_pos[q+1] - nan_pos[q]\n",
    "                for l in range(length):\n",
    "                    interval_f2[nan_pos[q] + l] = l\n",
    "\n",
    "            length = len(case) - nan_pos[-1]\n",
    "            for l in range(length):\n",
    "                interval_f2[nan_pos[-1] + l] = l\n",
    "            temp_data = np.column_stack((temp_data, interval_f2))\n",
    "\n",
    "        # Differential features\n",
    "        # These capture the change in values that have been recorded (quite simply as well but it should be just fine)\n",
    "        diff_f = sep_data.copy()\n",
    "        diff_f = diff_f.astype(float)\n",
    "        if len(nan_pos) <= 1:\n",
    "            diff_f[:] = np.NaN\n",
    "            temp_data = np.column_stack((temp_data, diff_f))\n",
    "        else:\n",
    "            diff_f[:nan_pos[1]] = np.NaN\n",
    "            for p in range(1, len(nan_pos)-1):\n",
    "                diff_f[nan_pos[p] : nan_pos[p+1]] = sep_data[nan_pos[p]] - sep_data[nan_pos[p-1]]\n",
    "            diff_f[nan_pos[-1]:] = sep_data[nan_pos[-1]] - sep_data[nan_pos[-2]]\n",
    "            temp_data = np.column_stack((temp_data, diff_f))\n",
    "    \n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b01ff8-e0f1-408d-8582-d1e35e53b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_slide_window(patient_data, columns):\n",
    "    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2975050-0b04-412e-bea6-a12702b2debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(patient_data):\n",
    "    # Get the column with Sepsis Label as it is not the same for each row (check documentation)\n",
    "    labels = np.array(patient_data['SepsisLabel'])\n",
    "    patient_data = patient_data.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Gets information from the missing variables \n",
    "    # This can be useful as it shows the clinical judgment, the test has not been ordered \n",
    "    #                              (probably a good decision we should take into account)\n",
    "    temp_data = feature_missing_information(patient_data, sep_col + con_col)\n",
    "    temp = pd.DataFrame(temp_data)\n",
    "    # To complete the data use forward-filling strategy\n",
    "    temp = temp.fillna(method='ffill')\n",
    "    # These are also the first set of features\n",
    "    # In this configutation 99 (66 + 33 or 3 per column) features to be precise\n",
    "    # They are also time indifferent\n",
    "    features_A = np.array(temp)\n",
    "\n",
    "    # six-hour slide window statistics of selected columns\n",
    "    columns = ['HR', 'O2Sat', 'SBP', 'MAP', 'Resp']\n",
    "    \n",
    "    \n",
    "    # Forward-Filling missing values\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8a3b1-2dbd-4a57-b3d1-e788e2e34604",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in set(dataset.index.get_level_values(0)):\n",
    "    patient_data = multiindex_df.loc[patient_id]\n",
    "    print(f\"Processing data for patient ID: {patient_id}, File: {patient_id_map[patient_id]}\", end='\\r')\n",
    "\n",
    "    features, labels = extract_features(patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfb1530-8fc5-4878-b7ee-312ee37f4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished imputing HR\n",
      "Finished imputing O2Sat\n",
      "Finished imputing SBP\n",
      "Finished imputing MAP\n",
      "Finished imputing DBP\n",
      "Finished imputing Resp\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Imputes O2Sat using linear interpolation\n",
    "# Other methods might be better based on the data distribution (consider Spline or Polynomial Interpolation)\n",
    "\n",
    "# Impute SBP using linear interpolation\n",
    "# We can consider Forward Fill or Backward Fill if we assume the blood pressure should remain relatively stable\n",
    "\n",
    "# Impute MAP using linear interpolation\n",
    "# To be more sophiscticated the data can be imputed with custom models to take into account SBP and DBP as there might be correlation\n",
    "\n",
    "# Impute DBP using linear interpolation\n",
    "# Same as SBP, we might consider Spline\n",
    "\n",
    "# Impute Resp using linear interpolation\n",
    "# Same as SBP and DBP, we might consider Spline or Polynomial Interpolation\n",
    "\n",
    "\n",
    "'''\n",
    "columns_to_linearly_interpolate = [\n",
    "    'HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp'\n",
    "]\n",
    "for column in columns_to_linearly_interpolate:\n",
    "    dataset = impute_linear_interpolation(dataset, column)\n",
    "    print('Finished imputing ' + column)\n",
    "\n",
    "columns_to_ffill = [\n",
    "    'Temp', 'Glucose', 'Potassium', 'Calcium', \n",
    "    'Magnesium', 'Chloride', 'Hct', 'Hgb', 'WBC', 'Platelets'\n",
    "]\n",
    "for column in columns_to_ffill:\n",
    "    dataset[column].ffill(inplace=True)\n",
    "'''\n",
    "\n",
    "# Columns not imputed\n",
    "\n",
    "# They dropped Bilirubin_direct, TroponinI, Fibrinogen\n",
    "#            has relation, more complex if any, potentially\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataset = dataset.fillna\n",
    "\n",
    "# Use forward filling for some of the data\n",
    "\n",
    "# Best solution used sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce06dbb-c245-4fbe-9ee4-14fff851a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_missing_information(patient_data, columns):\n",
    "    temp = patiend_data\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a50a2b-c1fb-4d03-8d95-9a441eced99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR\n",
      "O2Sat\n",
      "Temp\n",
      "SBP\n",
      "MAP\n",
      "DBP\n",
      "Resp\n",
      "EtCO2\n",
      "BaseExcess\n",
      "HCO3\n",
      "FiO2\n",
      "pH\n",
      "PaCO2\n",
      "SaO2\n",
      "AST\n",
      "BUN\n",
      "Alkalinephos\n",
      "Calcium\n",
      "Chloride\n",
      "Creatinine\n",
      "Bilirubin_direct\n",
      "Glucose\n",
      "Lactate\n",
      "Magnesium\n",
      "Phosphate\n",
      "Potassium\n",
      "Bilirubin_total\n",
      "TroponinI\n",
      "Hct\n",
      "Hgb\n",
      "PTT\n",
      "WBC\n",
      "Fibrinogen\n",
      "Platelets\n",
      "Age\n",
      "Gender\n",
      "Unit1\n",
      "Unit2\n",
      "HospAdmTime\n",
      "ICULOS\n",
      "SepsisLabel\n"
     ]
    }
   ],
   "source": [
    "for patient_id in set(dataset.index.get_level_values(0)):\n",
    "    patient_data = multiindex_df.loc[patient_id]\n",
    "    print(f\"Processing data for patient ID: {patient_id}, File: {patient_id_map[patient_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd45fea-fcd6-4ff6-a873-8f0cb1d74d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ectract features\n",
    "\n",
    "def extract_features(patient_data):\n",
    "    # Get the column with Sepsis Label as it is not the same for each row (check documentation)\n",
    "    labels = np.array(patient_data['SepsisLabel'])\n",
    "    patient_data = patient_data.drop(columns=['SepsisLabel', 'TroponinI'])\n",
    "\n",
    "    # Gets information from the missing variables \n",
    "    # This can be useful as it shows the clinical judgment, the test has not been ordered \n",
    "    #                              (probably a good decision we should take into account)\n",
    "    temp_data = feature_missing_information(patient_data, sep_col + con_col)\n",
    "    temp = pd.DataFrame(temp_data)\n",
    "    # To complete the data use forward-filling strategy\n",
    "    temp = temp.fillna(method='ffill')\n",
    "    # These are also the first set of features\n",
    "    # In this configutation 66 features to be precise\n",
    "    # They are also time indifferent\n",
    "    features_A = np.array(temp)\n",
    "    \n",
    "\n",
    "    # some code\n",
    "    # Forward-Filling missing values\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e65180-1e29-4c5b-b326-1a4c1bd55adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Run feature extraction for each patient\n",
    "\n",
    "for c in dataset.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e78e00-c2ca-44a5-a852-90ec02818979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1ed9b-9a12-4986-8bb3-6586eed290c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
